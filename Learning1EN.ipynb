{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd5V90l1jFBLa5peBUxxGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuelMorenoNeria/NeuralNetworks/blob/main/Learning1EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vjWXzG78niT",
        "outputId": "38ade0bd-d108-4029-a558-8efa49308ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2939 - accuracy: 0.9153\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1409 - accuracy: 0.9586\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1054 - accuracy: 0.9677\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9734\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0732 - accuracy: 0.9768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[2.3903854e-06, 1.7133017e-09, 7.1530048e-06, 5.7458255e-04,\n",
              "        1.1669977e-10, 1.0487272e-06, 4.6475926e-12, 9.9939513e-01,\n",
              "        7.2621287e-06, 1.2452525e-05],\n",
              "       [8.3289741e-08, 2.7912449e-05, 9.9993992e-01, 7.1662130e-06,\n",
              "        1.4549776e-13, 3.4212498e-08, 3.3411812e-08, 4.5742620e-12,\n",
              "        2.4816472e-05, 1.4072746e-11],\n",
              "       [5.5648167e-07, 9.9942386e-01, 6.4808133e-05, 1.8882631e-05,\n",
              "        5.2474919e-05, 2.3687726e-06, 1.1337046e-06, 2.7479816e-04,\n",
              "        1.6064032e-04, 4.7598124e-07],\n",
              "       [9.9997270e-01, 1.2382487e-09, 5.3775457e-06, 8.3051020e-08,\n",
              "        4.7213425e-07, 1.5033414e-06, 1.7135451e-05, 1.2950508e-06,\n",
              "        1.1423273e-07, 1.3594388e-06],\n",
              "       [1.3719880e-04, 6.2910934e-09, 2.9914061e-06, 1.0921597e-06,\n",
              "        9.9588627e-01, 4.2041042e-06, 9.3002373e-06, 1.5574144e-04,\n",
              "        6.8151221e-06, 3.7962650e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow\n",
        "print(\"TensorFlow version:\", tensorflow.__version__)\n",
        "# Load the MNIST dataset which consists of images of handwritten digits\n",
        "mnist = tensorflow.keras.datasets.mnist\n",
        "# Store the data in variables\n",
        "# x_train and x_test contain the images of the digits\n",
        "# y_train and y_test contain the corresponding labels\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Normalize pixel values to be between 0 and 1 instead of 0 to 255\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# Create the sequential model\n",
        "model = tensorflow.keras.models.Sequential([\n",
        "# Flatten layer that converts input (28x28 images) into a one-dimensional vector\n",
        "  tensorflow.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "# Layer with 128 neurons using ReLU activation function (if the value is negative, it returns zero, otherwise it returns the value)\n",
        "  tensorflow.keras.layers.Dense(128, activation='relu'),\n",
        "# Dropout layer that randomly deactivates 20% of neurons during training to prevent overfitting\n",
        "  tensorflow.keras.layers.Dropout(0.2),\n",
        "# Layer with 10 neurons, classifying digits from 0 to 9\n",
        "  tensorflow.keras.layers.Dense(10)\n",
        "])\n",
        "# Pass the first image in x_train to the model function, then add .numpy() to convert it to an array because it returns as a tensor\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "# Display the result\n",
        "predictions\n",
        "# Softmax converts predictions into probabilities and then prints them\n",
        "tensorflow.nn.softmax(predictions).numpy()\n",
        "# Defines the loss function to be used during model training\n",
        "# Logits are the direct output values of the last layer of the neural network before the softmax activation.\n",
        "# When from_logits=True, the loss function will internally perform normalization of logits to probabilities before calculating cross-entropy.\n",
        "loss_fn = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# Compute the loss between true labels and predictions\n",
        "loss_fn(y_train[:1], predictions).numpy()\n",
        "# Compile the model specifying the parameters to use\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "# Train the model on the training data for 5 epochs\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "# Create a new model consisting of the previous model followed by a Softmax layer to obtain the final prediction probabilities.\n",
        "probability_model = tensorflow.keras.Sequential([\n",
        "  model,\n",
        "  tensorflow.keras.layers.Softmax()\n",
        "])\n",
        "# Make predictions on the first 5 examples of the test dataset using the new model and return the predicted probabilities for each class.\n",
        "probability_model(x_test[:5])\n"
      ]
    }
  ]
}