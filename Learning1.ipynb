{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRkqrgc7y/Khu879Qy4byj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuelMorenoNeria/NeuralNetworks/blob/main/Learning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6GQgBmE1A1G",
        "outputId": "ba24eed1-2294-46c5-a0a5-e197ea3ebece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2970 - accuracy: 0.9146\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1430 - accuracy: 0.9585\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1064 - accuracy: 0.9683\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0877 - accuracy: 0.9726\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0749 - accuracy: 0.9764\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[6.0269819e-08, 2.1079150e-09, 2.9797964e-06, 3.3173594e-04,\n",
              "        2.0833070e-11, 3.8314067e-08, 1.0304972e-12, 9.9965584e-01,\n",
              "        3.4508666e-08, 9.2582959e-06],\n",
              "       [1.6155406e-08, 8.7865250e-05, 9.9984574e-01, 6.2923587e-05,\n",
              "        2.1668050e-13, 8.4423624e-07, 5.6903298e-07, 1.6249635e-11,\n",
              "        1.9667737e-06, 4.6228738e-13],\n",
              "       [4.1672702e-06, 9.9697101e-01, 8.6879352e-04, 7.5430631e-05,\n",
              "        2.3015412e-04, 1.6454869e-04, 7.6531811e-05, 9.2759897e-04,\n",
              "        6.7562243e-04, 5.9666813e-06],\n",
              "       [9.9854845e-01, 3.6958607e-08, 6.6011318e-04, 7.4545028e-06,\n",
              "        2.6654147e-06, 2.4358335e-06, 7.1716169e-04, 4.0362011e-05,\n",
              "        1.8582988e-07, 2.1230051e-05],\n",
              "       [1.1184097e-06, 1.5868823e-09, 1.8080239e-06, 2.5096051e-07,\n",
              "        9.9608338e-01, 2.2607303e-08, 4.2443307e-06, 2.8200539e-05,\n",
              "        3.0915144e-06, 3.8778572e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow\n",
        "print(\"TensorFlow version:\", tensorflow.__version__)\n",
        "#Cargamos el conjunto de datos MNIST que son imagenes de Numeros escritos a mano\n",
        "mnist = tensorflow.keras.datasets.mnist\n",
        "#Metemos los datos en variables\n",
        "#x_train y x_test contiene las imagenes de los digitos\n",
        "#y_train e y_test contiene las etiquetas correspondientes\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#Cambiamos los valores de los pixeles para que en lugar de estar entre el 0 y el 255 esten entre 0 y 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "#Creamos el modelo secuencial\n",
        "model = tensorflow.keras.models.Sequential([\n",
        "#Capa de aplanamiento que convierte la entrada (imágenes de 28x28) en un vector unidimensional.\n",
        "  tensorflow.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "#Capa de 128 neuronas con activacion RELU(si el valor es negativo devuelve cero, sino devuelve el valor)\n",
        "  tensorflow.keras.layers.Dense(128, activation='relu'),\n",
        "#Capa que desactiva aleatoriamente el 20% de las neuronas durante el entrenamiento para evitar el sobreajuste.\n",
        "  tensorflow.keras.layers.Dropout(0.2),\n",
        "#Capa de 10 neuronas, que clasifica los dígitos del 0 al 9.\n",
        "  tensorflow.keras.layers.Dense(10)\n",
        "])\n",
        "#Le paso a la funcion model la primera imagen que tenemos en x_train, luego hay que ponerle .numpy para que lo convierta en un array porque lo devuelve como un tensor\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "#Mostramos el resultado\n",
        "predictions\n",
        "#Softmax convierte las predicciones en probabilidades y luego las imprime\n",
        "tensorflow.nn.softmax(predictions).numpy()\n",
        "# Define la función de pérdida que se utilizará durante el entrenamiento del modelo.\n",
        "#Los logits son los valores de salida directos de la última capa de la red neuronal antes de la activación softmax.\n",
        "# Cuando from_logits=True, la función de pérdida realizará internamente la normalización de los logits a probabilidades antes de calcular la entropía cruzada.\n",
        "loss_fn = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#Calcula la pérdida entre las etiquetas verdaderas y las predicciones.\n",
        "loss_fn(y_train[:1], predictions).numpy()\n",
        "# COmpila el modelo especificando los parametros a usar\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "#Entrena el modelo en los datos de entrenamiento durante 5 épocas.\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "#Crea un nuevo modelo que consiste en el modelo anterior seguido de una capa Softmax para obtener las probabilidades finales de predicción.\n",
        "probability_model = tensorflow.keras.Sequential([\n",
        "  model,\n",
        "  tensorflow.keras.layers.Softmax()\n",
        "])\n",
        "#Realiza predicciones sobre los primeros 5 ejemplos del conjunto de datos de prueba utilizando el nuevo modelo y devuelve las probabilidades predichas para cada clase.\n",
        "probability_model(x_test[:5])"
      ]
    }
  ]
}